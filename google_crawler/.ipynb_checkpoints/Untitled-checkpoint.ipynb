{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['url_results/1', 'url_results/2', 'url_results/3', 'url_results/4', 'url_results/5', 'url_results/6', 'url_results/7', 'url_results/8', 'url_results/9', 'url_results/10', 'url_results/11', 'url_results/12', 'url_results/13', 'url_results/14', 'url_results/15', 'url_results/16', 'url_results/17', 'url_results/18', 'url_results/19', 'url_results/20', 'url_results/21', 'url_results/22', 'url_results/23', 'url_results/24', 'url_results/25', 'url_results/26', 'url_results/27', 'url_results/28', 'url_results/29', 'url_results/30']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "path = 'url_results/'\n",
    "list_name = []\n",
    "for file in os.listdir(path):            \n",
    "    #将多个路径组合后返回，即合并目录\t\n",
    "    file_path = os.path.join(path, file)  \n",
    "    if os.path.isdir(file_path):  \n",
    "        listdir(file_path, list_name)  \n",
    "    else:  \n",
    "        list_name.append(file_path)\n",
    "list_name\n",
    "def sort_key(s):\n",
    "    #sort_strings_with_embedded_numbers\n",
    "    re_digits = re.compile(r'(\\d+)')\n",
    "    pieces = re_digits.split(s)\n",
    "    pieces[1::2] = map(int, pieces[1::2])\n",
    "    return pieces\n",
    "# list = ['abc12.txt','abc9.txt','abc99.txt','abc100.txt','aaa999.txt','234.bat','detail.bat']\n",
    "list_name.sort(key=sort_key)\n",
    "print(list_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n",
      "275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "FinalResult=pd.DataFrame(columns=['CaseNumber','Website'])\n",
    "url_list = []\n",
    "caseNumber_list = []\n",
    "case = 1\n",
    "for i in range(len(list_name)):\n",
    "    url_file = open(list_name[i], 'r', encoding = 'UTF-8')\n",
    "    for line in url_file.readlines():\n",
    "        if line.startswith('url:'):\n",
    "            websiteName = ''\n",
    "            if line.find('url=') == -1:\n",
    "                websiteName = re.findall(r'\\//(.+?)\\/', line)[0]\n",
    "            else:\n",
    "                websiteName = re.findall(r'\\//(.+?)\\/', line.split('?')[1])[0]\n",
    "            url_list.append(websiteName)\n",
    "            caseNumber_list.append(str(case))\n",
    "    case = case + 1\n",
    "print(len(caseNumber_list))\n",
    "# print(len(url_list))caseNumber_list[j]\n",
    "url_list\n",
    "result = list(zip(caseNumber_list, url_list))\n",
    "print(len(result))\n",
    "for j in range(len(caseNumber_list)):\n",
    "    row = {'CaseNumber':caseNumber_list[j],'Website': url_list[j]}\n",
    "    FinalResult=FinalResult.append(row, ignore_index=True)\n",
    "    \n",
    "nowTime=datetime.datetime.now().strftime('%Y%m%d_%Hh%Mm%Ss')\n",
    "FinalResult.to_csv('C:\\\\Users\\\\25727\\\\liujiaxin_files\\\\'+'WebsiteAnalysis'+nowTime+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "website = Counter(url_list)\n",
    "print(len(website))\n",
    "website_count = sorted(website.items(), key = lambda d:d[1], reverse = True)\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "FinalResult2=pd.DataFrame(columns=['Website', 'Count'])\n",
    "for key in website_count:\n",
    "    row = {'Website':key,'Count': website_count[key]}\n",
    "    FinalResult2=FinalResult2.append(row, ignore_index=True)\n",
    "    \n",
    "nowTime=datetime.datetime.now().strftime('%Y%m%d_%Hh%Mm%Ss')\n",
    "FinalResult2.to_csv('C:\\\\Users\\\\25727\\\\liujiaxin_files\\\\'+'WebsiteCountAnalysis'+nowTime+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'commons.apache.org'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# signature = 'url:http://commons.apache.org/proper/commons-math/javadocs/api-3.6/org/apache/commons/math3/linear/DecompositionSolver.html'\n",
    "signature = 'url:http://www.google.com/url?url=http://commons.apache.org/proper/commons-math/javadocs/api-3.6/org/apache/commons/math3/geometry/euclidean/twod/Vector2D.html'\n",
    "if signature.find('url=') == -1:\n",
    "    websiteName = re.findall(r'\\//(.+?)\\/', signature)[0]            \n",
    "else:\n",
    "    websiteName = re.findall(r'\\//(.+?)\\/', signature.split('?')[1])[0]\n",
    "# methodName = re.findall(r'\\//(.+?)\\/', signature)[0]\n",
    "# methodName\n",
    "websiteName"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
